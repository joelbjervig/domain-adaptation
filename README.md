# Master's Thesis Project
### Unsupervised Image Classification Using Domain Adaptation Via the Second Order Statistics
![screen](misc/screen.png)

## Overview
This Master's thesis project was conducted at Scania and Uppsala University during spring/summer -22.

## The deep learning packages
The shallow CORAL method was implemented in Keras at the begining of the project, but pytorch was later favoured
for the deep CORAL model because its low-level accessability. Therefore you will find two folders, a keras folder
for the shallow CORAL method, and a pytorch folder for the deep CORAL model, with their seperate dependency requirements

## Shallow CORAL
CORAL (COrrelation ALignment) from "Return of Frustratingly Easy Domain Adaptation" by Sun et. al. ([link](https://arxiv.org/pdf/1511.05547.pdf)) is an unspuervised domain adaptation method which minimizes the domain shift
by aligning the second order statistics of the source features with that of the target features. A linear classifier will then
adapt to the target domain by learning in a supervised manner on the aligned source deep features.

### Required environment shallow CORAL
See [requirements_sc.txt](requirements_sc.txt) for full specification of 
platform, python and dependency packages. Run `pip install -r 
requirements_sc.txt` to install dependencies.

### Source Code shallow CORAL
- folder: deep_features
- folder: plots
- folder: weights
- main.py
- library.py
- coral.py
- data_loader.py
- losses.py
- nn_cifar_10.py
- nn_classifier.py

### Usage shallow CORAL
1) In `main.py` load weights from pretraining on Cifar-10 dataset to the neural network by setting `load_weights = True` in the `train_cifar10` function
2) Setting `do_CORAL = True` will align the camera deep features extracted from the last layer of the CNN in `train_cifar10`. Train the linear classifier or load weights to the classifier by either setting `load_weights = False` or `load_weights = True` in the `shallow_CORAL` function. 
3) Check the main function to check that the code both functions will be executed
4) Set `plotting = True` to plot TSNE plots and a confusion matrix.

## Deep CORAL
Deep CORAL from "Deep CORAL: Correlation Alignment for Deep Domain Adaptation" by Sun, B. & Saenko, K. ([link](https://arxiv.org/pdf/1607.01719.pdf)) constructs a joint loss function of the CORAL loss and the classification loss such that a convolutional neural net learns a deep, robust representation of the domain adaptation task.

### Required environment Deep CORAL
See [requirements_dc.txt](requirements_dc.txt) for full specification of 
platform, python and dependency packages. Run `pip install -r 
requirements_dc.txt` to install dependencies.

<pre><code>This is a code block.
</code></pre>

### Source code deep CORAL
- `data`:     folder containing the Cifar-10 dataset
- `models`:   folder containing model parameters from succesful training runs
- `plots`:    folder containing plots generated by plot_trainstats.py
- `train_stats`: folder contraining training history
- `cnn_torch_no_coral.py`: neural net model for supervised learning
- `cnn_torch.py`: neural net model for unsupervised domain adaptation
- `confusion_matrix.py`: creates and plots a confusion matrix
- `coral.py`: computes the CORAL loss
- `data_loader_our_data.py`: loads the Cifar-10, camera, and LiDAR data
- `deep_coral.py`: main script to train a DA model, to perform hyperparameter tuning of lambda in jpint loss function
- `no_deep_coral.py`: main script for supervised training of neural net model on camera data. i.e. finetuning.
- `our_utils.py`: create and preprocess camera and LiDAR datasets
- `plot_trainstats.py`: a range of code snippets that plots training metrics and results from the hyperparameter tuning
- `target_accuracy.py`: computes classification accuracy of a model on the LiDAR test data
- `plot_dataset_images.py`: creates and plots a collage of ten images per class, in one image.

### Usage Deep CORAL
1) In the main function of `deep_coral.py`, there are several boolean variables that controls which code will be executed
    - sd
    - sf
    - sg
    - 
3) 
4)
5)

## Report
[Web](http://35.227.117.218/)  
[Slides](https://docs.google.com/presentation/d/e/2PACX-1vT5Qs8ly5csvfrqpafVQ4H0pQTr0U1S1XYF1gudEBVSxXaMwgUgVN4zEBDhO11j3d2Td7VmJ_PK6VGJ/pub?start=false&loop=false&delayms=3000)  
[Report](misc/articlix-final-report.pdf)

## License

[MIT](LICENSE)
